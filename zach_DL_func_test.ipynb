{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e99033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "## \n",
    "## testing the functions zach wrote for data download\n",
    "## doesn't use wget and fully \"pythonized\" - uses requests instead\n",
    "## using asf api to generate URLS\n",
    "\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import zipfile\n",
    "import getpass\n",
    "from osgeo import gdal \n",
    "import os  # for chdir, getcwd, path.basename, path.exists\n",
    "import pandas as pd # for DatetimeIndex\n",
    "import codecs # for text parsing code\n",
    "import netrc\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show # plotting raster data\n",
    "from rasterio.plot import show_hist #histograms of raster data\n",
    "import glob\n",
    "import requests\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE, Popen\n",
    "from os.path import join, isdir, isfile, basename\n",
    "import progressbar\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44601ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Username:  jacktarricone\n",
      "Enter Password:  ············\n"
     ]
    }
   ],
   "source": [
    "# input NASA Earthdata credentials here\n",
    "ASF_USER = input(\"Enter Username: \")\n",
    "ASF_PASS = getpass.getpass(\"Enter Password: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281d8e0c-ba14-4fa1-a890-a9838e737c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c31d6a-9e2c-43ac-8dc6-665bef35dad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Logger __main__ (WARNING)>\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66bfae",
   "metadata": {},
   "source": [
    "### Function definitions to query ASF APi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c4a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bbox_string(polygon):\n",
    "    '''\n",
    "    Builds the string to include in the ASF search request. The bbox consists of 4 comma-separated numbers: lower left longitude,latitude, and upper right longitude,latitude.\n",
    "    \n",
    "    Parmeters\n",
    "    ----------\n",
    "    polygon: shapely polygon\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    polygon_string : string\n",
    "        String to include in the ASF request\n",
    "    '''\n",
    "    points = mapping(polygon)['coordinates'][0]\n",
    "    lower_left = points[0]\n",
    "    upper_right = points[2]\n",
    "    bbox_string = f'{lower_left[0]},{lower_left[1]},{upper_right[0]},{upper_right[1]}'\n",
    "        \n",
    "    return bbox_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3652bf-c7b9-4abf-a1ac-2905e0d6960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_asf(platform, processingLevel, start, end, polygon, output_format):\n",
    "    '''\n",
    "    Search the ASF platform for images given the input parameters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        platform : string\n",
    "            Name of the imaging platform. Defaults to UAVSAR, but a list of supported platform is available on the ASF website\n",
    "        processingLevel : string\n",
    "            Processing level of the imaging product. \n",
    "            Possible values for UAVSAR : (KMZ, PROJECTED, PAULI, PROJECTED_ML5X5, STOKES, AMPLITUDE, BROWSE, COMPLEX, DEM_TIFF, PROJECTED_ML3X3, METADATA, AMPLITUDE_GRD, INTERFEROMETRY, INTERFEROMETRY_GRD, THUMBNAIL)\n",
    "        start : datetime object\n",
    "            Start date of the search period.\n",
    "        end : datetime object\n",
    "            End date of the search period.\n",
    "        polygon : shapely polygon defining the Area of Interest,\n",
    "        output_format: string\n",
    "            Format being returned by the ASF API. Values : CSV, JSON, KML, METALINK, COUNT, DOWNLOAD, GEOJSON\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Ouputs a search file\n",
    "    '''\n",
    "    base = 'https://api.daac.asf.alaska.edu/services/search/param'\n",
    "    start_date = start.strftime('%Y-%m-%dT%H:%M:%SUTC')\n",
    "    end_date = end.strftime('%Y-%m-%dT%H:%M:%SUTC')\n",
    "    aoi_string = build_bbox_string(polygon)\n",
    "    payload = {\n",
    "        'platform': platform,\n",
    "        'processingLevel': processingLevel,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'bbox': aoi_string,\n",
    "        'output': output_format\n",
    "    }\n",
    "    r = requests.get(base, params=payload)\n",
    "    \n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3fa148-1528-4df8-8c21-49af62481134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_download(url, output_f):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        url: url to download\n",
    "        output_f: path to save the data to\n",
    "    \"\"\"\n",
    "    print(f\"\\n\\nDownloading {url}\\nSaving to {output_f}\")\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        #bar = progressbar.ProgressBar(max_value=progressbar.UnknownLength)\n",
    "        with open(output_f, 'wb') as f:\n",
    "            for i, chunk in tqdm(enumerate(r), description = f'Downloading {basename(url)}'):\n",
    "                f.write(chunk)\n",
    "                #bar.update(i)\n",
    "    else:\n",
    "        print(f\"HTTP CODE {r.status_code}. Skipping download!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2096cbea-1b95-4666-a26b-b17ce07c866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_InSAR(url, output_dir, polarizations=['HH', 'HV', 'VH', 'VV'],\n",
    "                    file_types=['amp1', 'amp2', 'cor', 'int']):\n",
    "    \"\"\"\n",
    "    Downloads uavsar InSAR files from a url.\n",
    "    Args:\n",
    "        url (string): A url containing uavsar flight data. Can be from JPL or ASF\n",
    "        output_dir (string): Directory to save the data in\n",
    "    Returns:\n",
    "        None\n",
    "    Raises:\n",
    "        ValueError: If the base flight name is missing the polarization HH\n",
    "    \"\"\"\n",
    "    log.info('Starting download of {url}...')\n",
    "\n",
    "    local = join(output_dir, basename(url))\n",
    "    # Checks for existence of url\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.HTTPError as e:\n",
    "        log.warning(f'{url} returned {e}')\n",
    "\n",
    "    # Make the output dir if it doesn't exist\n",
    "    if not isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    if not isfile(local):\n",
    "        stream_download(url, local)\n",
    "    else:\n",
    "        log.info(f\"{local} already exists, skipping download!\")\n",
    "\n",
    "    # Download the ann file always.\n",
    "    ext = url.split('.')[-2]\n",
    "    ann_url = url.replace(f\"{ext}.grd\", \"ann\")\n",
    "    ann_local = local.replace(f\"{ext}.grd\", \"ann\")\n",
    "\n",
    "    if not isfile(ann_local):\n",
    "        stream_download(ann_url, ann_local)\n",
    "    else:\n",
    "        log.info(f\"{ann_local} already exists, skipping download!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4459e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search parameters for sierra flight line\n",
    "sierra_polygon = Polygon([(-119.9697,37.4631),(-118.9576,37.4631),(-118.9576,38.7211),(-119.969,38211)])\n",
    "start_date = datetime.strptime('2020-02-28 11:00:00', '%Y-%m-%d %H:%M:%S') \n",
    "end_date = datetime.strptime('2020-03-11 11:00:00', '%Y-%m-%d %H:%M:%S') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd735df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 product(s) found\n"
     ]
    }
   ],
   "source": [
    "# query API to generate one over pass\n",
    "results = search_asf(platform='UAVSAR', processingLevel='INTERFEROMETRY_GRD', \n",
    "                    start=start_date, end=end_date, polygon=sierra_polygon, output_format='JSON')[0]\n",
    "\n",
    "# print number of products\n",
    "print(f'{len(results)} product(s) found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ebf63dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://datapool.asf.alaska.edu/INTERFEROMETRY_GRD/UA/sierra_17305_20014-000_20016-005_0014d_s01_L090_01_int_grd.zip\n"
     ]
    }
   ],
   "source": [
    "# define url\n",
    "for i in results:\n",
    "        downloadUrl = i['downloadUrl']\n",
    "        print(downloadUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35d7d1-ebdb-41d6-a725-3bb855ef63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_InSAR(url = downloadUrl, \n",
    "               output_dir = '/Users/jacktarricone/Desktop/zach_test/',\n",
    "               polarizations = ['HH'],\n",
    "               file_types=['amp1', 'amp2', 'cor', 'int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50f772d3-f4e3-4d30-8971-0326a35d13fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://datapool.asf.alaska.edu/INTERFEROMETRY_GRD/UA/sierra_17305_20014-000_20016-005_0014d_s01_L090_01_int_grd.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloadUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37fbd0-5c1e-4129-86e4-7767b6d48c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde0136-ca27-4656-a0f5-2c0f8351fb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new path for folder of insar data just downloaded\n",
    "new_path_list = glob.glob('/Users/jacktarricone/ch2_sierra_data/sierra/*')\n",
    "new_path = new_path_list[3] # select first list elemet\n",
    "print(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd172d8c-6a1d-4e42-9dd8-b4d92325f86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5cfadb-9bf9-43e3-a007-aa3e7ff67b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddc872-16d4-4c8a-a875-91e8c62ddebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19265e1-f59e-4deb-81c0-9956226bae49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff78e034-2d4f-41ba-aeb0-c590a4fa299b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cde922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert files to geotiffs and save in same folder\n",
    "uavsar_tiff_convert(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted files\n",
    "os.chdir(new_path)\n",
    "grd = glob.glob('*.grd') #define .grd\n",
    "hdr = glob.glob('*.hdr*') #define .hdr\n",
    "int_file = glob.glob('*.int*') #define .int\n",
    "\n",
    "# remove both\n",
    "for f in grd:\n",
    "    os.remove(f)\n",
    "    \n",
    "for f in hdr:\n",
    "    os.remove(f)\n",
    "    \n",
    "for f in int_file:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf438b-21d9-4e9b-9b23-9b976dbabd28",
   "metadata": {},
   "source": [
    "## Define only the HH files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102351b-32b1-4e91-9a48-b8efac1cbb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence\n",
    "for cor in glob.glob(\"*HH*cor.grd.tif\"):\n",
    "    print(cor)\n",
    "\n",
    "# unwrapped phase\n",
    "for unw in glob.glob(\"*HH*unw.grd.tif\"):\n",
    "    print(unw)\n",
    "\n",
    "# dem used in processing\n",
    "for dem in glob.glob(\"*HH*hgt.grd.tif\"):\n",
    "    print(dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ed33d-b822-4431-bc72-61d0b9de26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open using rio\n",
    "cor_rast = rio.open(cor)\n",
    "unw_rast = rio.open(unw)\n",
    "dem_rast = rio.open(dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8286264-b2c6-43e8-9e75-47d56c5525c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test plot\n",
    "show(cor_rast)\n",
    "show(unw_rast)\n",
    "show(dem_rast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b7a2a-6074-4e36-9c08-680486ae72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unw\n",
    "with rio.open(unw) as unw_raw:\n",
    "    unw_array = unw_raw.read(1)\n",
    "\n",
    "# convert all 0's to nan\n",
    "unw_array[unw_array==0] = np.nan\n",
    "\n",
    "#cor\n",
    "with rio.open(cor) as cor_raw:\n",
    "    cor_array = cor_raw.read(1)\n",
    "\n",
    "cor_array[cor_array==0] = np.nan\n",
    "\n",
    "#dem, no data value is -10000\n",
    "with rio.open(dem) as dem_raw:\n",
    "    dem_array = dem_raw.read(1)\n",
    "\n",
    "dem_array[dem_array == -10000] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c128a18c-f2fc-4206-a0d6-300a5267699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot NaN corrected data\n",
    "show(unw_array)\n",
    "show(cor_array)\n",
    "show(dem_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6ead7-b9a9-46e4-847e-c2f641fe7875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_env]",
   "language": "python",
   "name": "conda-env-test_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
