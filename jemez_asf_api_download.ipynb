{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e567927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import zipfile\n",
    "import getpass\n",
    "from osgeo import gdal \n",
    "import os  # for chdir, getcwd, path.basename, path.exists\n",
    "import pandas as pd # for DatetimeIndex\n",
    "import codecs # for text parsing code\n",
    "import netrc\n",
    "import rasterio as rio\n",
    "import glob\n",
    "import requests\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE, Popen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1944b",
   "metadata": {},
   "source": [
    "### Credentials setup for EarthData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb32f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Username: jacktarricone\n",
      "Enter Password: ········\n"
     ]
    }
   ],
   "source": [
    "ASF_USER = input(\"Enter Username: \")\n",
    "ASF_PASS = getpass.getpass(\"Enter Password: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8f69e",
   "metadata": {},
   "source": [
    "### Function definitions to query ASF APi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24c039a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bbox_string(polygon):\n",
    "    '''\n",
    "    Builds the string to include in the ASF search request. The bbox consists of 4 comma-separated numbers: lower left longitude,latitude, and upper right longitude,latitude.\n",
    "    \n",
    "    Parmeters\n",
    "    ----------\n",
    "    polygon: shapely polygon\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    polygon_string : string\n",
    "        String to include in the ASF request\n",
    "    '''\n",
    "    points = mapping(polygon)['coordinates'][0]\n",
    "    lower_left = points[0]\n",
    "    upper_right = points[2]\n",
    "    bbox_string = f'{lower_left[0]},{lower_left[1]},{upper_right[0]},{upper_right[1]}'\n",
    "        \n",
    "    return bbox_string\n",
    "\n",
    "def search_asf(platform, processingLevel, start, end, polygon, output_format):\n",
    "    '''\n",
    "    Search the ASF platform for images given the input parameters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        platform : string\n",
    "            Name of the imaging platform. Defaults to UAVSAR, but a list of supported platform is available on the ASF website\n",
    "        processingLevel : string\n",
    "            Processing level of the imaging product. \n",
    "            Possible values for UAVSAR : (KMZ, PROJECTED, PAULI, PROJECTED_ML5X5, STOKES, AMPLITUDE, BROWSE, COMPLEX, DEM_TIFF, PROJECTED_ML3X3, METADATA, AMPLITUDE_GRD, INTERFEROMETRY, INTERFEROMETRY_GRD, THUMBNAIL)\n",
    "        start : datetime object\n",
    "            Start date of the search period.\n",
    "        end : datetime object\n",
    "            End date of the search period.\n",
    "        polygon : shapely polygon defining the Area of Interest,\n",
    "        output_format: string\n",
    "            Format being returned by the ASF API. Values : CSV, JSON, KML, METALINK, COUNT, DOWNLOAD, GEOJSON\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Ouputs a search file\n",
    "    '''\n",
    "    base = 'https://api.daac.asf.alaska.edu/services/search/param'\n",
    "    start_date = start.strftime('%Y-%m-%dT%H:%M:%SUTC')\n",
    "    end_date = end.strftime('%Y-%m-%dT%H:%M:%SUTC')\n",
    "    aoi_string = build_bbox_string(polygon)\n",
    "    payload = {\n",
    "        'platform': platform,\n",
    "        'processingLevel': processingLevel,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'bbox': aoi_string,\n",
    "        'output': output_format\n",
    "    }\n",
    "    r = requests.get(base, params=payload)\n",
    "    \n",
    "    return r.json()\n",
    "\n",
    "def download_single_product(productUrl, path):\n",
    "    '''\n",
    "    Downloading function.\n",
    "    \n",
    "    Paramters\n",
    "    ----------\n",
    "    productUrl: string\n",
    "            Product download Url\n",
    "    path: string\n",
    "            path to download product to\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    Download the file\n",
    "    '''\n",
    "    process = Popen(['wget', productUrl, f'--user={ASF_USER}', f'--password={ASF_PASS}', '-P', path, '--progress=bar'], stderr=PIPE)\n",
    "    started = False\n",
    "    for line in process.stderr:\n",
    "        line = line.decode(\"utf-8\", \"replace\")\n",
    "        if started:\n",
    "            splited = line.split()\n",
    "            if len(splited) == 9:\n",
    "                percentage = splited[6]\n",
    "                speed = splited[7]\n",
    "                remaining = splited[8]\n",
    "                print(\"Downloaded {} with {} per second and {} left.\".format(percentage, speed, remaining), end='\\r')\n",
    "        elif line == os.linesep:\n",
    "            started = True\n",
    "    print(f\"\\nDone downloading {productUrl}\")\n",
    "    \n",
    "def search_and_bulk_download(platform, processingLevel, start, end, polygon, path):\n",
    "    '''\n",
    "    Search the ASF platform for images given the input parameters. Download found products\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        platform : string\n",
    "            Name of the imaging platform. Defaults to UAVSAR, but a list of supported platform is available on the ASF website\n",
    "        processingLevel : string\n",
    "            Processing level of the imaging product. \n",
    "            Possible values for UAVSAR : (KMZ, PROJECTED, PAULI, PROJECTED_ML5X5, STOKES, AMPLITUDE, BROWSE, COMPLEX, DEM_TIFF, PROJECTED_ML3X3, METADATA, AMPLITUDE_GRD, INTERFEROMETRY, INTERFEROMETRY_GRD, THUMBNAIL)\n",
    "        start : datetime object\n",
    "            Start date of the search period.\n",
    "        end : datetime object\n",
    "            End date of the search period.\n",
    "        polygon : shapely polygon defining the Area of Interest,\n",
    "        path: string\n",
    "            Path to download product to\n",
    "        '''\n",
    "    results = search_asf(platform, processingLevel, start, end, polygon, output_format='JSON')[0]\n",
    "    print(f'{len(results)} product(s) found')\n",
    "    for result in results:\n",
    "        downloadUrl = result['downloadUrl']\n",
    "        download_single_product(downloadUrl, path)\n",
    "        print('Unzipping product')\n",
    "        with zipfile.ZipFile(path + result['fileName'], 'r') as zip_ref:\n",
    "            zip_ref.extractall(path + result['productName'])\n",
    "        print('Deleting original .zip')\n",
    "        os.remove(path + result['fileName'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb625d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder is path to a folder with an .ann (or .txt) and .grd files (.amp1, .amp2, .cor, .unw, .int)\n",
    "\n",
    "def uavsar_tiff_convert(folder, verbose = False):\n",
    "    \"\"\"\n",
    "    Builds a header file for the input UAVSAR .grd file,\n",
    "    allowing the data to be read as a raster dataset.\n",
    "    :param folder:   the folder containing the UAVSAR .grd and .ann files\n",
    "    \"\"\"\n",
    "\n",
    "    os.chdir(folder)\n",
    "\n",
    "    # Empty lists to put information that will be recalled later.\n",
    "    Lines_list = []\n",
    "    Samples_list = []\n",
    "    Latitude_list = []\n",
    "    Longitude_list = []\n",
    "    Files_list = []\n",
    "\n",
    "    # Step 1: Look through folder and determine how many different flights there are\n",
    "    # by looking at the HDR files.\n",
    "    for files in os.listdir(folder):\n",
    "        if files [-4:] == \".grd\":\n",
    "            newfile = open(files[0:-4] + \".hdr\", 'w')\n",
    "            newfile.write(\"\"\"ENVI\n",
    "description = {DESCFIELD}\n",
    "samples = NSAMP\n",
    "lines = NLINE\n",
    "bands = 1\n",
    "header offset = 0\n",
    "data type = DATTYPE\n",
    "interleave = bsq\n",
    "sensor type = UAVSAR L-Band\n",
    "byte order = 0\n",
    "map info = {Geographic Lat/Lon, \n",
    "            1.000, \n",
    "            1.000, \n",
    "            LON, \n",
    "            LAT,  \n",
    "            0.0000555600000000, \n",
    "            0.0000555600000000, \n",
    "            WGS-84, units=Degrees}\n",
    "wavelength units = Unknown\n",
    "                \"\"\"\n",
    "                          )\n",
    "            newfile.close()\n",
    "            if files[0:18] not in Files_list:\n",
    "                Files_list.append(files[0:18])\n",
    "\n",
    "    #Variables used to recall indexed values.\n",
    "    var1 = 0\n",
    "\n",
    "    #Step 2: Look through the folder and locate the annotation file(s).\n",
    "    # These can be in either .txt or .ann file types.\n",
    "    for files in os.listdir(folder):\n",
    "        if Files_list[var1] and files[-4:] == \".txt\" or files[-4:] == \".ann\":\n",
    "            #Step 3: Once located, find the info we are interested in and append it to\n",
    "            # the appropriate list. We limit the variables to <=1 so that they only\n",
    "            # return two values (one for each polarization of\n",
    "            searchfile = codecs.open(files, encoding = 'windows-1252', errors='ignore')\n",
    "            for line in searchfile:\n",
    "                if \"Ground Range Data Latitude Lines\" in line:\n",
    "                    Lines = line[65:70]\n",
    "                    if verbose:\n",
    "                        print(f\"Number of Lines: {Lines}\")\n",
    "                    if Lines not in Lines_list:\n",
    "                        Lines_list.append(Lines)\n",
    "\n",
    "                elif \"Ground Range Data Longitude Samples\" in line:\n",
    "                    Samples = line[65:70]\n",
    "                    if verbose:\n",
    "                        print(f\"Number of Samples: {Samples}\")\n",
    "                    if Samples not in Samples_list:\n",
    "                        Samples_list.append(Samples)\n",
    "\n",
    "                elif \"Ground Range Data Starting Latitude\" in line:\n",
    "                    Latitude = line[65:85]\n",
    "                    if verbose:\n",
    "                        print(f\"Top left lat: {Latitude}\")\n",
    "                    if Latitude not in Latitude_list:\n",
    "                        Latitude_list.append(Latitude)\n",
    "\n",
    "                elif \"Ground Range Data Starting Longitude\" in line:\n",
    "                    Longitude = line[65:85]\n",
    "                    if verbose:\n",
    "                        print(f\"Top left Lon: {Longitude}\")\n",
    "                    if Longitude not in Longitude_list:\n",
    "                        Longitude_list.append(Longitude)\n",
    "    \n",
    "                        \n",
    "                 \n",
    "            #Reset the variables to zero for each different flight date.\n",
    "            var1 = 0\n",
    "            searchfile.close()\n",
    "\n",
    "\n",
    "    # Step 3: Open .hdr file and replace data for all type 4 (real numbers) data\n",
    "    # this all the .grd files expect for .int\n",
    "    for files in os.listdir(folder):\n",
    "        if files[-4:] == \".hdr\":\n",
    "            with open(files, \"r\") as sources:\n",
    "                lines = sources.readlines()\n",
    "            with open(files, \"w\") as sources:\n",
    "                for line in lines:\n",
    "                    if \"data type = DATTYPE\" in line:\n",
    "                        sources.write(re.sub(line[12:19], \"4\", line))\n",
    "                    elif \"DESCFIELD\" in line:\n",
    "                        sources.write(re.sub(line[15:24], folder, line))\n",
    "                    elif \"lines\" in line:\n",
    "                        sources.write(re.sub(line[8:13], Lines, line))\n",
    "                    elif \"samples\" in line:\n",
    "                        sources.write(re.sub(line[10:15], Samples, line))\n",
    "                    elif \"LAT\" in line:\n",
    "                        sources.write(re.sub(line[12:15], Latitude, line))\n",
    "                    elif \"LON\" in line:\n",
    "                        sources.write(re.sub(line[12:15], Longitude, line))\n",
    "                    else:\n",
    "                        sources.write(re.sub(line, line, line))\n",
    "    \n",
    "    # Step 3: Open .hdr file and replace data for .int file date type 6 (complex)                 \n",
    "    for files in os.listdir(folder):\n",
    "        if files[-8:] == \".int.hdr\":\n",
    "            with open(files, \"r\") as sources:\n",
    "                lines = sources.readlines()\n",
    "            with open(files, \"w\") as sources:\n",
    "                for line in lines:\n",
    "                    if \"data type = 4\" in line:\n",
    "                        sources.write(re.sub(line[12:13], \"6\", line))\n",
    "                    elif \"DESCFIELD\" in line:\n",
    "                        sources.write(re.sub(line[15:24], folder, line))\n",
    "                    elif \"lines\" in line:\n",
    "                        sources.write(re.sub(line[8:13], Lines, line))\n",
    "                    elif \"samples\" in line:\n",
    "                        sources.write(re.sub(line[10:15], Samples, line))\n",
    "                    elif \"LAT\" in line:\n",
    "                        sources.write(re.sub(line[12:15], Latitude, line))\n",
    "                    elif \"LON\" in line:\n",
    "                        sources.write(re.sub(line[12:15], Longitude, line))\n",
    "                    else:\n",
    "                        sources.write(re.sub(line, line, line))\n",
    "                        \n",
    "    \n",
    "    # Step 4: Now we have an .hdr file, the data is geocoded and can be loaded into python with rasterio\n",
    "    # once loaded in we use gdal.Translate to convert and save as a .tiff\n",
    "    \n",
    "    data_to_process = glob.glob(os.path.join(folder, '*.grd')) # list all .grd files\n",
    "    for data_path in data_to_process: # loop to open and translate .grd to .tiff, and save .tiffs using gdal\n",
    "        raster_dataset = gdal.Open(data_path, gdal.GA_ReadOnly)\n",
    "        raster = gdal.Translate(os.path.join(folder, os.path.basename(data_path) + '.tif'), raster_dataset, format = 'Gtiff', outputType = gdal.GDT_Float32)\n",
    "    \n",
    "    # Step 5: Save the .int raster, needs separate save because of the complex format\n",
    "    data_to_process = glob.glob(os.path.join(folder, '*.int.grd')) # list all .int.grd files (only 1)\n",
    "    for data_path in data_to_process:\n",
    "        raster_dataset = gdal.Open(data_path, gdal.GA_ReadOnly)\n",
    "        raster = gdal.Translate(os.path.join(folder, os.path.basename(data_path) + '.tif'), raster_dataset, format = 'Gtiff', outputType = gdal.GDT_CFloat32)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e55f1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (886004525.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/7d/61kbxptj5yl29nbrh216cv_40000gn/T/ipykernel_23175/886004525.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    jemez_polygon = Polygon([(-106.7272 35.7211),(-106.2372 35.7211),(-106.2372 36.0658),(-106.7272 36.0658)])\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# jemez polygon for testing purposes (bounding box info from .ann)\n",
    "jemez_polygon = Polygon([(-106.56, 36.02), (-106.33, 36.02), (-108.0001, 39.0256), (-106.56, 35.75), (-106.33, 35.75907871)])\n",
    "\n",
    "POLYGON([(-106.7272 35.7211),(-106.2372 35.7211),(-106.2372 36.0658),(-106.7272 36.0658)])\n",
    "\n",
    "start_date = datetime.strptime('2020-02-10 11:00:00', '%Y-%m-%d %H:%M:%S') \n",
    "end_date = datetime.strptime('2020-03-07 11:00:00', '%Y-%m-%d %H:%M:%S') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5f2fccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9184bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_asf(platform='UAVSAR', processingLevel='INTERFEROMETRY_GRD', \n",
    "                    start=start_date, end=end_date, polygon=jemez_polygon, output_format='JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "568147c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absoluteOrbit': '-1',\n",
       " 'beamMode': 'RPI',\n",
       " 'beamModeType': 'RPI',\n",
       " 'beamSwath': None,\n",
       " 'browse': 'https://datapool.asf.alaska.edu/BROWSE/UA/Haywrd_05522_18038-020_20024-028_0773d_s01_L090HH_01.cor.png',\n",
       " 'catSceneId': None,\n",
       " 'centerLat': '37.3542894629861',\n",
       " 'centerLon': '-121.826207207041',\n",
       " 'collectionName': 'Hayward Fault, CA',\n",
       " 'configurationName': 'Repeat Pass Interferometry',\n",
       " 'doppler': '-1',\n",
       " 'downloadUrl': 'https://datapool.asf.alaska.edu/INTERFEROMETRY_GRD/UA/Haywrd_05522_18038-020_20024-028_0773d_s01_L090_01_int_grd.zip',\n",
       " 'farEndLat': '37.5757346',\n",
       " 'farEndLon': '-121.20051869',\n",
       " 'farStartLat': '36.96680004',\n",
       " 'farStartLon': '-122.30211664',\n",
       " 'faradayRotation': None,\n",
       " 'fileName': 'Haywrd_05522_18038-020_20024-028_0773d_s01_L090_01_int_grd.zip',\n",
       " 'finalFrame': '747',\n",
       " 'firstFrame': '747',\n",
       " 'flightDirection': None,\n",
       " 'flightLine': '05522',\n",
       " 'formatName': None,\n",
       " 'frameNumber': '747',\n",
       " 'frequency': None,\n",
       " 'granuleName': 'UA_Haywrd_05522_18038-020_20024-028_0773d_s01_L090_01',\n",
       " 'granuleType': 'UAVSAR_INSAR_SCENE',\n",
       " 'groupID': 'UA_Haywrd_05522_18038-020_20024-028_0773d_s01_L090_01',\n",
       " 'incidenceAngle': None,\n",
       " 'insarGrouping': '-1',\n",
       " 'insarStackSize': '0',\n",
       " 'lookDirection': 'L',\n",
       " 'masterGranule': None,\n",
       " 'md5sum': 'cfe5a4ecc40287cc95b8927f81c10eb6',\n",
       " 'missionName': 'Hayward Fault, CA',\n",
       " 'nearEndLat': '37.73985706',\n",
       " 'nearEndLon': '-121.34484332',\n",
       " 'nearStartLat': '37.12994427',\n",
       " 'nearStartLon': '-122.44796382',\n",
       " 'offNadirAngle': '-1',\n",
       " 'percentCoherence': None,\n",
       " 'percentTroposphere': None,\n",
       " 'percentUnwrapped': None,\n",
       " 'platform': 'UAVSAR',\n",
       " 'pointingAngle': None,\n",
       " 'polarization': 'HH',\n",
       " 'processingDate': '2020-09-24T20:52:20Z',\n",
       " 'processingDescription': 'Ground projected interferogram product, one file per pair of repeat tracks, complex floating point format 8 bytes per pixel, little endian.',\n",
       " 'processingLevel': 'INTERFEROMETRY_GRD',\n",
       " 'processingType': 'L1',\n",
       " 'processingTypeDisplay': 'Ground Projected Interferogram',\n",
       " 'productName': 'UA_Haywrd_05522_18038-020_20024-028_0773d_s01_L090_01',\n",
       " 'product_file_id': 'UA_Haywrd_05522_18038-020_20024-028_0773d_s01_L090_01-INTERFEROMETRY_GRD',\n",
       " 'relativeOrbit': '05522',\n",
       " 'sarSceneId': None,\n",
       " 'sceneDate': '2020-09-10T01:03:46Z',\n",
       " 'sceneDateString': None,\n",
       " 'sceneId': 'UA_Haywrd_05522_18038-020_20024-028_0773d_s01_L090_01',\n",
       " 'sensor': 'UAVSAR',\n",
       " 'sizeMB': '1025.31056595',\n",
       " 'slaveGranule': None,\n",
       " 'startTime': '2018-07-30T19:09:43Z',\n",
       " 'status': None,\n",
       " 'stopTime': '2020-09-10T01:03:46Z',\n",
       " 'stringFootprint': 'POLYGON((-121.344843 37.739857,-121.200519 37.575735,-122.302117 36.966800,-122.447964 37.129944,-121.344843 37.739857))',\n",
       " 'thumbnailUrl': 'https://datapool.asf.alaska.edu/THUMBNAIL/UA/Haywrd_05522_18038-020_20024-028_0773d_s01_L090HH_01.amp1_THUMBNAIL.jpg',\n",
       " 'track': '05522',\n",
       " 'varianceTroposphere': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed0e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_env]",
   "language": "python",
   "name": "conda-env-test_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
