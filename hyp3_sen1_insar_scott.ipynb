{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "racial-leisure",
   "metadata": {},
   "source": [
    "# Process an interferogram with ASF HyP3\n",
    "\n",
    "https://hyp3-docs.asf.alaska.edu/using/sdk/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-fluid",
   "metadata": {},
   "source": [
    "## Search for scenes\n",
    "\n",
    "scenes over grand mesa, colorado using https://asf.alaska.edu/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shapely.geometry\n",
    "\n",
    "roi = shapely.geometry.box(-108.3,39.2,-107.8,38.8)\n",
    "polygonWKT = roi.wkt\n",
    "\n",
    "baseurl = \"https://api.daac.asf.alaska.edu/services/search/param\"\n",
    "\n",
    "data = dict(\n",
    "    intersectsWith=polygonWKT,\n",
    "    platform='Sentinel-1',\n",
    "    processingLevel=\"SLC\",\n",
    "    beamMode='IW',\n",
    "    output='json',\n",
    "    start='2020-10-30T11:59:59Z',\n",
    "    end='2020-11-30T11:59:59Z',\n",
    "    #relativeOrbit=None,\n",
    "    #flightDirection=None,\n",
    ")\n",
    "\n",
    "r = requests.get(baseurl, params=data, timeout=100)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results into pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(r.json()[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easier to explore the inventory in plots\n",
    "import hvplot.pandas\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "\n",
    "formatter = DatetimeTickFormatter(years='%m-%d')\n",
    "timeseries = df.hvplot.scatter(x='startTime', y='relativeOrbit', c='relativeOrbit',\n",
    "                               xformatter=formatter,\n",
    "                               title='Acquisition times (UTC)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "import panel as pn\n",
    "\n",
    "gf_aoi = gpd.GeoDataFrame(geometry=[roi])\n",
    "polygons = df.stringFootprint.apply(shapely.wkt.loads)\n",
    "gf_footprints = gpd.GeoDataFrame(df, crs=\"EPSG:4326\", geometry=polygons)\n",
    "\n",
    "tiles = gv.tile_sources.StamenTerrainRetina.options(width=600, height=400)\n",
    "aoi = gf_aoi.hvplot(geo=True, fill_color=None, line_color='m', hover=False)\n",
    "footprints = gf_footprints.hvplot.polygons(geo=True, legend=False, alpha=0.2, c='relativeOrbit', title='Sentinel-1 Tracks') \n",
    "\n",
    "mapview = tiles * footprints * aoi\n",
    "\n",
    "pn.Column(mapview,timeseries)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "confidential-monroe",
   "metadata": {},
   "source": [
    "From the plots above we can choose a pair that has:\n",
    "1. good spatial coverage of our area of interest\n",
    "2. a timespan of interest \n",
    "\n",
    "So let's use relativeOrbit=129 2020-11-11 and 2020-10-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.relativeOrbit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit = '129'\n",
    "reference = '2020-11-11'\n",
    "secondary = '2020-10-30'\n",
    "\n",
    "dfS = df[df.relativeOrbit == orbit]\n",
    "granule1 = dfS.loc[dfS.sceneDate.str.startswith(reference), 'granuleName'].values[0]\n",
    "granule2 = dfS.loc[dfS.sceneDate.str.startswith(secondary), 'granuleName'].values[0]\n",
    "print(f'granule1: {granule1}')\n",
    "print(f'granule2: {granule2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref in [reference, secondary]:\n",
    "    print(dfS.loc[dfS.sceneDate.str.startswith(ref), 'downloadUrl'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-reception",
   "metadata": {},
   "source": [
    "## Process an InSAR pair (interferogram)\n",
    "\n",
    "examples:\n",
    "- https://nbviewer.jupyter.org/github/ASFHyP3/hyp3-sdk/blob/main/docs/sdk_example.ipynb\n",
    "- https://hyp3-docs.asf.alaska.edu/using/sdk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyp3_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~/.netrc file used for credentials\n",
    "hyp3 = hyp3_sdk.HyP3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing quota\n",
    "hyp3.check_quota() #199 (200 scenes per month?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = hyp3.submit_insar_job(granule1,\n",
    "                            granule2,\n",
    "                            name='gm_20201111_20201030', \n",
    "                            include_los_displacement=True, \n",
    "                            include_inc_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All jobs you've submitted\n",
    "# NOTE: processing w/ defaults uses INSAR_GAMMA \n",
    "# NOTE: re-run this cell to update results of batch job\n",
    "batch = hyp3.find_jobs()\n",
    "job = batch.jobs[0] # most recent job\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have lists of dictionaries, visualizing with a pandas dataframe is convenient\n",
    "df = pd.DataFrame([job.to_dict() for job in batch])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually no, expiration time is not available for download...\n",
    "#pd.to_datetime(df.expiration_time[0]) - pd.to_datetime(df.request_time[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportError: IProgress not found. Please update jupyter and ipywidgets.\n",
    "# but I think this still succeeeds\n",
    "job.download_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires ipywidgets\n",
    "#hyp3.watch(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-story",
   "metadata": {},
   "source": [
    "## Process multiple pairs in batch mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with progress bar\n",
    "#from tqdm.auto import tqdm \n",
    "\n",
    "#insar_jobs = sdk.Batch()\n",
    "#for reference in tqdm(granules):\n",
    "#    neighbors_metadata = asf_search.get_nearest_neighbors(reference, max_neighbors=2)\n",
    "#    for secondary_metadata in neighbors_metadata:\n",
    "#        insar_jobs += hyp3.submit_insar_job(reference, secondary_metadata['granuleName'], name='insar-example')\n",
    "#print(insar_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also submit jobs via web interface # Can also visit https://hyp3.asf.alaska.edu/pending_products \n",
    "# Which then shows logs that can be sorted into 'submitted, failed, etc...'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
